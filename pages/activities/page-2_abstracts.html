<!doctype html>
<html lang="de" data-bs-theme="auto">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description"
      content="The Applied Generative AI in Digital Humanities (AGKI-DH) working group focuses on exploring and showcasing the applications of generative AI, especially Large Language Models (LLMs), in digital humanities. This includes both commercial and open-source models, recognizing the significant advancements and the widespread discussion on AI issues like bias, hallucination, high computational footprint, data security, and potential destructive capabilities. Amidst these challenges, the group aims to harness the opportunities in AI development for digital humanities, fostering an ongoing exchange on core AI concepts and practical experiences. It seeks collaboration with other groups on greening (AI footprint), digital humanities theory, and empowerment (ethical aspects). The goals include identifying, assessing, and categorizing generative AI applications in digital humanities, establishing best practices, developing evaluation criteria, facilitating discussions and knowledge exchange, and balancing opportunities and risks.">
    <meta name="keywords"
      content="Generative AI, Digital Humanities, Dhd, Large Language Models, Open Source AI, AI in Humanities, Best Practices in AI">
    <meta name="author" content="Christopher Pollin, Gerrit Brüning">
    <title>Abstracts zum Workshop: Generative KI in den Digitalen Geisteswissenschaften</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@docsearch/css@3">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css"
      rel="stylesheet"
      integrity="sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH"
      crossorigin="anonymous">
    <link rel="stylesheet" href="../assets/style.css">
  </head>
  <body>
    <header data-bs-theme="dark" class="fixed-top">
      <div class="navbar navbar-dark bg-dark shadow-sm">
        <div class="container">
          <a href="../../index.html" class="navbar-brand d-flex align-items-center fs-3">
            <strong>AGKI-DH</strong>
          </a>
        </div>
      </div>
    </header>
    <main>
      <section class="py-5 text-center container">
        <div class="row py-lg-5">
          <div class="col-lg-6 col-md-8 mx-auto">
            <h1 class="fw-light">Abstracts zum Workshop<br />(Generative) KI für Kultur- und
              Textdaten<br>
              Weimar, 4./5. November 2024 <a href="page-2.html">(Programm)</a></h1>
          </div>
        </div>
      </section>
      <div class="container py-5">
        <section class="mt-4">
          <h2><strong>Intuition vs. Präzision – LLMs in der Ontologieentwicklung</strong><br>
            Harald Sack, Karlsruhe</h2>
          <p>Die Entwicklung präziser und aussagekräftiger Ontologien erfordert eine enge
            Zusammenarbeit zwischen Ontologieexperten und Domain-Spezialisten. Der erforderliche
            Wissenstransfer zwischen diesen Gruppen ist oft zeitaufwendig und komplex. Large
            Language Models (LLMs) bieten vielversprechende Ansätze, um diesen Prozess zu
            automatisieren und zu beschleunigen. In verschiedenen Phasen des Ontologie-Lebenszyklus
            können LLMs unterstützen, beispielsweise bei der Generierung von Begriffsvorschlägen,
            der Überprüfung von Konsistenzen oder der Erstellung von Definitionen. Der Vortrag
            beleuchtet verschiedene Einsatzmöglichkeiten von LLMs in der Ontologieentwicklung,
            diskutiert dabei sowohl Chancen als auch Risiken und präsentiert erste Ergebnisse aus
            aktuellen Forschungsprojekten.</p>
        </section>
        <section class="mt-4">
          <h2><strong>Named Entity Recognition und Linking in deutschsprachigen Zeitungstexten – Wie
              können (L)LMs unterstützen?</strong><br> Pia Schwarz, Mannheim</h2>
          <p>Um auf sprachwissenschaftliche Fragen Antwort zu finden, braucht es vor allem eine gute
            Datengrundlage. Bezogen auf Textdaten sind diese im besten Fall ausreichend annotiert
            und gut durchsuchbar. Textkorpora wie das Deutsche Referenzkorpus DeReKo[1] mit großen
            Mengen an Zeitungstexten bieten eine hervorragende Datenquelle – verlinkte Entitäten
            sind dort allerdings noch nicht vorhanden. Mit Modellen für Named Entity Recognition
            können automatisiert Eigennamen annotiert und diese Ergebnisse wiederum mithilfe von
            Entity Linking Modellen verlinkt werden: beispielsweise mit Datenbanken wie Wikidata
            oder der Gemeinsamen Normdatei, die zusätzlichen Kontext zu einer Entität liefern. Im
            Idealfall werden so weitere Zusammenhänge aufgedeckt und Entitäten besser disambiguiert.
            Im Fall von DeReKo ließen sich dann gezielt thematisch zusammenhängende Subsets des
            Gesamtkorpus extrahieren. In diesem Beitrag werden mehrere Entity Linker für
            deutschsprachige Texte evaluiert und beleuchtet, inwiefern generative große
            Sprachmodelle dabei unterstützen können.</p>
          <p>[1] Leibniz-Institut für Deutsche Sprache (2024): Deutsches Referenzkorpus / Archiv der
            Korpora geschriebener Gegenwartssprache 2024-I-RC3 (RC vom 13.03.2024). Mannheim:
            Leibniz-Institut für Deutsche Sprache. www.ids-mannheim.de/dereko</p>
        </section>
        <section class="mt-4">
          <h2><strong>Wieso, weshalb, warum? Explainable Artificial Intelligence in der
              Kunstgeschichte</strong><br> Stefanie Schneider, München</h2>
          <p>Selbst traditionell hermeneutisch geprägte Disziplinen wie die Kunstgeschichte widmen
            sich seit einigen Jahren dem Objekt in Form seiner digitalen Repräsentation, die in
            semantisch dichte Vektorräume eingeschrieben wird. Die Prozesse dieser Transformation
            sind jedoch aufgrund des Black-Box-Charakters fortgeschrittener künstlicher neuronaler
            Netze – wie etwa Large Vision Models (LVMs) – für kunsthistorische Analysen häufig
            intransparent. So ist z.B. unklar, warum bestimmte Kunstwerke bei einer Text- oder
            Bildabfrage in Retrieval-Aufgaben, die auf der Repräsentation des Objekts basieren, als
            relevant klassifiziert werden. In diesem Vortrag sollen daher Methoden aus dem Bereich
            der Explainable Artificial Intelligence (XAI) motiviert werden, um zu besser
            interpretierbaren Klassifikations- und Retrieval-Ergebnissen für die kunsthistorische
            Forschung zu gelangen. Eingesetzt werden dazu Methoden zur Hervorhebung
            entscheidungsrelevanter Bildregionen.</p>
        </section>
        <section class="mt-4">
          <h2><!-- v.d.Bussche --></h2>
          <p></p>
        </section>
        <section class="mt-4">
          <h2><strong>Generative Sprachmodelle in interpretativen Konstellationen: Annäherungen über
              den Bedeutungsbegriff</strong><br> Rabea Kleymann, Chemnitz / Julian Schröter,
            München</h2>
          <p>Im gegenwärtigen Diskurs über Funktion und Einsatz großer generativer Sprachmodelle
            gewinnen die Begriffe der Interpretation und Interpretierbarkeit an Relevanz. So werden
            Sprachmodelle nicht nur selbst als interpretationsbedürftig wahrgenommen. Vielmehr
            verändern sie auch unser Nachdenken über geisteswissenschaftliche
            Interpretationsverfahren. Der Vortrag nimmt nun diese neuen interpretativen
            Konstellationen zum Ausgangspunkt, um nach dem Bedeutungsbegriff zu fragen. Wie und wo
            wird Bedeutung im Sprachmodell repräsentiert und transformiert? Wie prägt der
            Bedeutungsbegriff die diskursiven Formationen über KI? Anhand von konkreten
            Fallbeispielen untersucht der Vortrag einzelne Bausteine der sozio-technischen
            Architektur von Sprachmodellen, wie das Transformermodell, den Tokenizer oder die
            Trainingsdatensätze. Dabei zeigt der Vortrag auf, wie diese neuen interpretativen
            Konstellationen Prozesse der geisteswissenschaftlichen Bedeutungsgenerierung sowie
            unsere Auffassungen von Textrepräsentation und Sprache beeinflussen.</p>
        </section>
        <section class="mt-4">
          <h2><strong>Mehr Licht – Die Auswertung mittelalterlicher Quellen mit Hilfe von
              LLMs</strong><br> Clemens Beck / Clemens Beckstein / Robert Gramsch-Stehfest /
            Johannes Mitschunas, Jena</h2>
          <p>Das sogenannte Repertorium Germanicum (RG) ist eine Edition von Verwaltungsschriftgut
            der spätmittelalterlichen Kirche. Diese Quelle bietet ein reichhaltiges und
            vielschichtiges Bild der spätmittelalterlichen Kirche, einschließlich ihrer religiösen
            und kanonisch-rechtlichen Grundlagen, organisatorischen und fiskalischen Mechanismen,
            personellen und räumlichen Netzwerke sowie politischen Ambitionen und Alltagsrealitäten.
            Die extrem verdichteten lateinischen Regesten des RG sind jedoch Fluch und Segen
            zugleich: Ein Fluch, weil sie Uneingeweihte und selbst viele professionelle Historiker
            verwirren oder abschrecken können, und ein Segen, weil sie den formelhaften Gehalt der
            Papstschreiben platzsparend und übersichtlich wiedergeben, ohne wesentliche inhaltliche
            Abstriche machen zu müssen. </p>
          <p>Bisher mussten die lateinischen Regesten in einem mühsamen Prozess händisch ausgewertet
            werden. In unserem Vortrag stellen wir die Einsatzmöglichkeiten von Künstlicher
            Intelligenz bei der Auswertung des Repertorium Germanicum in der Forschung unserer
            interdisziplinären Arbeitsgruppe MEPHIsto („Digitale Modelle, Erklärungen und Prozesse
            in den Historischen Wissenschaften“) vor. </p>
          <p>Wir zeigen in unserem Vortrag exemplarisch auf, wie wir Large Language Models für die
            Named Entity Recognition, die Extraktion von historischen Informationen aus den
            lateinischen Regesten und der Umwandlung der Informationen in Factoids einsetzen.
            Daneben diskutieren wir, wie wir die LLMs auch für die Entwicklung einer Ontologie für
            die Personen- und Rechtsgeschichte der spätmittelalterlichen Kirche einsetzen. </p>
        </section>
        <section class="mt-4">
          <h2><!-- Rack --></h2>
          <p></p>
        </section>
        <section class="mt-4">
          <h2><strong>(Generative) Künstliche Intelligenz als Herausforderung für die digitalen
              Geisteswissenschaften – Roundtable-Diskussion</strong><br> Paul M. Näger, Münster /
            Tessa Gengnagel, Köln / Lina Franken, Vechta</h2>
          <p>Die im Workshop diskutierten Anwendungen von (Generativer) Künstlicher Intelligenz
            geben Anlass zu grundsätzlicheren Fragen an die Forschung und zur Rolle von Forschenden
            innerhalb, aber auch jenseits des Felds der digitalen Geisteswissenschaften (DH):</p>
          <ol class="list-group">
            <li class="list-group-item"><strong>Modell und Wissen:</strong> Wie verhalten sich
              Annahmen zur Wissens- und Weltrepräsentation in KI-Modellen zu bestehenden DH-Theorien
              und wie lassen sich diese Diskurse zusammenführen? Welche Auswirkungen haben sie auf
              die Datenmodellierung und -manipulation geisteswissenschaftlicher Wissensdomänen?</li>
            <li class="list-group-item"><strong>Verantwortung und Ethik:</strong> Wie könnte eine
              angemessene Wissenschaftsethik für das KI-Zeitalter aussehen? Stellen KI-Systeme unser
              Verständnis und vertraute Redeweisen von Transparenz, Erklärbarkeit und Verantwortung
              in Frage? Auf welche ethischen Aspekte müssen geisteswissenschaftlich Forschende bei
              der Anwendung von KI in ihren Projekten besonders achten?</li>
            <li class="list-group-item"><strong>Menschlicher Anteil und Bias:</strong> Welche
              Perspektiven, die in KI-basierter Forschung zum Ausdruck kommen, sind durch und mit
              menschlicher Interaktion entstanden, etwa durch die Erstellung von gelabelten
              Datensätzen, und wie sollte dies in der Anwendung berücksichtigt werden? Inwiefern
              kann und sollte Bias thematisiert werden? Welche Auswirkung sollte die Nutzung durch
              KI-Modelle darauf haben, ob und wenn ja welche Datensätze in Open Access-Formaten zur
              Verfügung gestellt werden?</li>
          </ol>
          <p>Zur Entfaltung und Diskussion der genannten Fragen versammelt das Roundtable drei
            Positionen aus den Feldern DH-Theorie (Tessa Gengnagel), Philosophie (Paul Näger) und
            digitale Kulturwissenschaft (Lina Franken).</p>
        </section>
      </div>
    </main>
    <footer class="text-body-secondary py-5">
      <div class="container">
        <p class="mb-1">AG Angewandte Generative KI in den Digitalen Geisteswissenschaften
          (AGKI-DH)</p>
        <p class="mb-1">2024. Convenors: Christopher Pollin, Gerrit Brüning, Sarah Oberbichler</p>
        <p class="mb-0">Based on <a href="https://getbootstrap.com/">Bootstrap 5</a></p>
      </div>
    </footer>
    <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.8/dist/umd/popper.min.js" integrity="sha384-I7E8VVD/ismYTF4hNIPjVp/Zjvgyol6VFvRkX/vR+Vc4jQkC+hVqc2pM8ODewa9r" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-YvpcrYf0tY3lHB60NNkmXc5s9fDVZLESaAA55NDzOxhy9GkcIdslK1eN7N6jIeHz" crossorigin="anonymous"></script>
  </body>
</html>
